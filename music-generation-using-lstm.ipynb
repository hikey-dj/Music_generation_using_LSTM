{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fe9a8e",
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": false,
    "execution": {
     "iopub.execute_input": "2024-04-14T09:04:48.105128Z",
     "iopub.status.busy": "2024-04-14T09:04:48.104774Z",
     "iopub.status.idle": "2024-04-14T09:05:04.969037Z",
     "shell.execute_reply": "2024-04-14T09:05:04.967853Z"
    },
    "papermill": {
     "duration": 16.875999,
     "end_time": "2024-04-14T09:05:04.971567",
     "exception": false,
     "start_time": "2024-04-14T09:04:48.095568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install pretty_midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d55e7b97",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-14T09:05:04.990738Z",
     "iopub.status.busy": "2024-04-14T09:05:04.990451Z",
     "iopub.status.idle": "2024-04-14T09:05:06.031253Z",
     "shell.execute_reply": "2024-04-14T09:05:06.030216Z"
    },
    "papermill": {
     "duration": 1.052867,
     "end_time": "2024-04-14T09:05:06.033689",
     "exception": false,
     "start_time": "2024-04-14T09:05:04.980822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pretty_midi\n",
    "import collections\n",
    "import datetime\n",
    "import glob\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e97ee062",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T09:05:06.052346Z",
     "iopub.status.busy": "2024-04-14T09:05:06.051954Z",
     "iopub.status.idle": "2024-04-14T09:05:06.061766Z",
     "shell.execute_reply": "2024-04-14T09:05:06.061058Z"
    },
    "papermill": {
     "duration": 0.020974,
     "end_time": "2024-04-14T09:05:06.063565",
     "exception": false,
     "start_time": "2024-04-14T09:05:06.042591",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def midi_to_notes(midi_file):\n",
    "    try:\n",
    "        midi = pretty_midi.PrettyMIDI(midi_file)\n",
    "    except:\n",
    "        return pd.DataFrame([])\n",
    "    \n",
    "    notes = collections.defaultdict(list)\n",
    "\n",
    "    # Get the list of instrument program numbers\n",
    "    program_numbers = np.arange(0,128)\n",
    "    \n",
    "    # One-hot encode the instrument program numbers\n",
    "    num_instruments = len(program_numbers)\n",
    "    one_hot_encoded_instruments = np.eye(num_instruments)\n",
    "    \n",
    "    # Create a dictionary mapping each instrument's program number to its one-hot encoded vector\n",
    "    program_to_one_hot = {program: one_hot_encoded_instruments[i] for i, program in enumerate(program_numbers)}\n",
    "    \n",
    "    all_notes = []\n",
    "    for instrument in midi.instruments:\n",
    "        for note in instrument.notes:\n",
    "            all_notes.append((note,instrument.program))\n",
    "        \n",
    "    sorted_notes = sorted(all_notes, key=lambda note: note[0].start)\n",
    "    prev_start = sorted_notes[0][0].start\n",
    "\n",
    "    for note_tuple in sorted_notes:\n",
    "        note = note_tuple[0]\n",
    "        program = note_tuple[1]\n",
    "        start = note.start\n",
    "        end = note.end\n",
    "        # Append instrument data\n",
    "        notes['instrument'].append(one_hot_encoded_instruments[program])\n",
    "        notes['pitch'].append(one_hot_encoded_instruments[note.pitch])\n",
    "        notes['start'].append(start)\n",
    "        #print(start,end,program)\n",
    "        notes['end'].append(end)\n",
    "        notes['step'].append(start - prev_start)\n",
    "        notes['duration'].append(end - start)\n",
    "\n",
    "        prev_start = start\n",
    "\n",
    "    return pd.DataFrame(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9af7f76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T09:05:06.081582Z",
     "iopub.status.busy": "2024-04-14T09:05:06.081311Z",
     "iopub.status.idle": "2024-04-14T09:05:06.087295Z",
     "shell.execute_reply": "2024-04-14T09:05:06.086477Z"
    },
    "papermill": {
     "duration": 0.017233,
     "end_time": "2024-04-14T09:05:06.089125",
     "exception": false,
     "start_time": "2024-04-14T09:05:06.071892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pre_process(notes, sequence_length=50):\n",
    "    # Scale pitch values\n",
    "    scaled_notes = notes.copy()  # Create a copy to avoid modifying the original array\n",
    "    # scaled_notes[:,-3] /= 128 \n",
    "    # Initialize input and output arrays\n",
    "    \n",
    "    n = len(scaled_notes)\n",
    "    note_input = np.zeros((max(0, n - sequence_length), sequence_length, scaled_notes.shape[1]))\n",
    "    note_output = np.zeros((max(0, n - sequence_length), scaled_notes.shape[1]))\n",
    "    #print(note_input.shape,note_output.shape,scaled_notes.shape,scaled_notes[:sequence_length].shape)\n",
    "    # Populate input and output arrays\n",
    "    for i in range(n - sequence_length):\n",
    "        note_input[i] = scaled_notes[i:i + sequence_length]\n",
    "        note_output[i] = scaled_notes[i + sequence_length]\n",
    "    \n",
    "    return note_input, note_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d63df083",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T09:05:06.106800Z",
     "iopub.status.busy": "2024-04-14T09:05:06.106541Z",
     "iopub.status.idle": "2024-04-14T09:05:06.205609Z",
     "shell.execute_reply": "2024-04-14T09:05:06.204848Z"
    },
    "papermill": {
     "duration": 0.110477,
     "end_time": "2024-04-14T09:05:06.207868",
     "exception": false,
     "start_time": "2024-04-14T09:05:06.097391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "files = []\n",
    "for dirname, _, filenames in os.walk('/kaggle/input/musicnet-dataset/musicnet_midis/musicnet_midis'):\n",
    "    for filename in filenames:\n",
    "        files.append(os.path.join(dirname, filename))\n",
    "random.shuffle(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b59234d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T09:05:06.227188Z",
     "iopub.status.busy": "2024-04-14T09:05:06.226884Z",
     "iopub.status.idle": "2024-04-14T09:05:06.233312Z",
     "shell.execute_reply": "2024-04-14T09:05:06.232495Z"
    },
    "papermill": {
     "duration": 0.017677,
     "end_time": "2024-04-14T09:05:06.235287",
     "exception": false,
     "start_time": "2024-04-14T09:05:06.217610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/input/musicnet-dataset/musicnet_midis/musicnet_midis/Ravel/2179_gr_rqtf3.mid'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33198057",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T09:05:06.253486Z",
     "iopub.status.busy": "2024-04-14T09:05:06.253235Z",
     "iopub.status.idle": "2024-04-14T09:05:06.260837Z",
     "shell.execute_reply": "2024-04-14T09:05:06.260052Z"
    },
    "papermill": {
     "duration": 0.018825,
     "end_time": "2024-04-14T09:05:06.262727",
     "exception": false,
     "start_time": "2024-04-14T09:05:06.243902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fetch_files(n,files,num_files):\n",
    "    start = n % len(files)\n",
    "    end = min(len(files),n+num_files)\n",
    "    all_notes = []\n",
    "    for file in files[start:end]:\n",
    "        notes = midi_to_notes(file)\n",
    "        all_notes.append(notes)\n",
    "    all_notes = pd.concat(all_notes)\n",
    "\n",
    "    #key_order = ['instrument','pitch', 'step', 'duration']\n",
    "    key_order = ['pitch', 'step', 'duration']\n",
    "    try:\n",
    "        train_notes = np.stack([all_notes[key] for key in key_order], axis=1)\n",
    "    except:\n",
    "        return [],[]\n",
    "    train_notes = train_notes.tolist()\n",
    "    for i,train_note in enumerate(train_notes):\n",
    "        train_notes[i] = np.concatenate((train_notes[i][0],train_notes[i][1:]))\n",
    "\n",
    "    train_notes = np.array(train_notes)\n",
    "    #print(type(train_notes))\n",
    "\n",
    "    del all_notes\n",
    "    #print(train_notes[15:20],\"\\nLength is: \",len(train_notes))\n",
    "\n",
    "    note_input,note_output = pre_process(train_notes)\n",
    "    del train_notes\n",
    "    return note_input, note_output\n",
    "    #print(note_input[0],\"\\nOUTPUT:\\n\",note_output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c38f440",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T09:05:06.280713Z",
     "iopub.status.busy": "2024-04-14T09:05:06.280475Z",
     "iopub.status.idle": "2024-04-14T09:05:06.288853Z",
     "shell.execute_reply": "2024-04-14T09:05:06.288079Z"
    },
    "papermill": {
     "duration": 0.019474,
     "end_time": "2024-04-14T09:05:06.290711",
     "exception": false,
     "start_time": "2024-04-14T09:05:06.271237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def accuracy(model,test_loader):\n",
    "    model.eval()\n",
    "    correct_instruments = 0\n",
    "    total_instruments = 0\n",
    "    correct_pitch = 0\n",
    "    total_pitch = 0\n",
    "    loss_step = 0\n",
    "    loss_duration = 0\n",
    "    i = 0\n",
    "\n",
    "    # Calculate accuracy for instruments\n",
    "    for inputs, targets in test_loader:\n",
    "\n",
    "        predictions = model(inputs)\n",
    "\n",
    "        #_, predicted_instruments = predictions[:, :128].max(dim=1)\n",
    "        #_, target_instruments = targets[:, :128].max(dim=1)\n",
    "        #_, predicted_pitch = predictions[:, 128:256].max(dim=1)\n",
    "        #_, target_pitch = targets[:, 128:256].max(dim=1)\n",
    "        _, predicted_pitch = predictions[:, :128].max(dim=1)\n",
    "        _, target_pitch = targets[:, :128].max(dim=1) \n",
    "        predicted_step = predictions[:, -2]\n",
    "        target_step = targets[:, -2]\n",
    "        predicted_duration = predictions[:, -1]\n",
    "        target_duration = targets[:, -1]\n",
    "        #predicted_pitch = (predictions[:, 128] * 128).int()\n",
    "        #target_pitch = (targets[:, 128] * 128).int()\n",
    "        #if(i<1):\n",
    "            #print(predictions[0],\"\\n\\n\",target_instruments)\n",
    "            #print(predicted_pitch,\"\\n\\n\",target_pitch)\n",
    "        i+=1\n",
    "        #correct_instruments += torch.sum(predicted_instruments == target_instruments).item()\n",
    "        #total_instruments += target_instruments.size(0)\n",
    "        correct_pitch += torch.sum(predicted_pitch == target_pitch).item()\n",
    "        total_pitch += target_pitch.size(0)\n",
    "        loss_step += F.l1_loss(predicted_step, target_step)\n",
    "        loss_duration += F.l1_loss(predicted_duration, target_duration)\n",
    "        \n",
    "    #accuracy_instruments = (correct_instruments / total_instruments)\n",
    "    accuracy_pitch = (correct_pitch / total_pitch)\n",
    "    \n",
    "    # Overall accuracy\n",
    "    #overall_accuracy = (correct_instruments + correct_pitch) / (total_instruments + total_pitch)\n",
    "\n",
    "    #print(f'Accuracy for instruments: {accuracy_instruments:.2%}')\n",
    "    #print(f'\\tAccuracy for pitch: {accuracy_pitch:.2%}')\n",
    "    #print(f'\\tLoss for step: {loss_step/i:.2}')\n",
    "    #print(f'\\tLoss for duration: {loss_duration/i:.2}')\n",
    "    return accuracy_pitch*100\n",
    "    #print(f'Overall accuracy: {overall_accuracy:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ebd71b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T08:28:04.220884Z",
     "iopub.status.busy": "2024-04-14T08:28:04.220102Z",
     "iopub.status.idle": "2024-04-14T08:28:04.267889Z",
     "shell.execute_reply": "2024-04-14T08:28:04.266736Z",
     "shell.execute_reply.started": "2024-04-14T08:28:04.220828Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2024-04-14T09:05:06.299218",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# import torch_xla.debug.metrics as met\n",
    "# import torch_xla.distributed.data_parallel as dp\n",
    "# import torch_xla.distributed.parallel_loader as pl\n",
    "# import torch_xla.utils.utils as xu\n",
    "# import torch_xla.core.xla_model as xm\n",
    "# import torch_xla.distributed.xla_multiprocessing as xmp\n",
    "# import torch_xla.test.test_utils as test_utils\n",
    "#import torch_xla.core.xla_model as xm\n",
    "\n",
    "\n",
    "class MusicGenerator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=2, dropout=0.1):\n",
    "        super(MusicGenerator, self).__init__()        \n",
    "        # LSTM layers\n",
    "        self.lstm1 = nn.LSTM(input_size, hidden_size, num_layers=num_layers, batch_first=True, dropout=dropout, bidirectional=False)\n",
    "        #self.dropout = nn.Dropout(p = 0.3)\n",
    "        #self.lstm2 = nn.LSTM(hidden_size, hidden_size, num_layers=num_layers, batch_first=True, dropout=dropout, bidirectional=False)\n",
    "        # Fully connected layers\n",
    "        self.fcP = nn.Linear(hidden_size, output_size-2)\n",
    "        self.reluP = nn.ReLU()\n",
    "        self.fcS = nn.Linear(hidden_size, 1)\n",
    "        self.reluS = nn.ReLU()\n",
    "        self.fcD = nn.Linear(hidden_size,1)\n",
    "        self.reluD = nn.ReLU()\n",
    "        # Softmax layers for instrument and pitch predictions\n",
    "        #self.softmax_instrument = nn.Softmax(dim=1)\n",
    "        self.softmax_pitch = nn.Softmax(dim=1)\n",
    "        \n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for layer in [self.fcP, self.fcS, self.fcD]:\n",
    "            nn.init.xavier_normal_(layer.weight)\n",
    "            nn.init.constant_(layer.bias, 0.0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # LSTM layers\n",
    "        out, _ = self.lstm1(x)\n",
    "        #out= self.dropout(out)\n",
    "        #out, _ = self.lstm2(out)\n",
    "        #out, _ = self.lstm3(out)\n",
    "        # Fully connected layers\n",
    "        outP = self.fcP(out[:,-1,:])  # Take the last time step's output\n",
    "        outP = self.reluP(outP)\n",
    "        outS = self.fcS(out[:,-1,:])\n",
    "        outS = self.reluS(outS)\n",
    "        outD = self.fcD(out[:,-1,:])\n",
    "        outD = self.reluD(outD)\n",
    "        # Apply softmax to get probabilities for instrument prediction\n",
    "        #instrument_probs = self.softmax_instrument(out[:, :128])\n",
    "        # Apply softmax to get probabilities for pitch prediction\n",
    "        pitch_probs = self.softmax_pitch(outP)\n",
    "\n",
    "        # Keep step and duration as they are\n",
    "        #step_duration = out[:, 256:]\n",
    "        output = torch.cat((pitch_probs,outS,outD), dim=1)\n",
    "        #output = pitch_probs\n",
    "        #output = out\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Initialize your model\n",
    "model = MusicGenerator(130,256,130)\n",
    "#model = MusicGenerator(note_input.shape[2],256,130)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = xm.xla_device()\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea824f16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T06:27:08.188551Z",
     "iopub.status.busy": "2024-04-14T06:27:08.187683Z",
     "iopub.status.idle": "2024-04-14T06:27:08.208737Z",
     "shell.execute_reply": "2024-04-14T06:27:08.207700Z",
     "shell.execute_reply.started": "2024-04-14T06:27:08.188513Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "print(\"\\tInitial: \",torch.cuda.memory_allocated(),torch.cuda.memory_reserved())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b56260",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T08:28:09.560951Z",
     "iopub.status.busy": "2024-04-14T08:28:09.560169Z",
     "iopub.status.idle": "2024-04-14T08:28:09.571554Z",
     "shell.execute_reply": "2024-04-14T08:28:09.570598Z",
     "shell.execute_reply.started": "2024-04-14T08:28:09.560916Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class CustomWeightedLoss(nn.Module):\n",
    "    def __init__(self, weights):\n",
    "        super(CustomWeightedLoss, self).__init__()\n",
    "        self.weights = weights\n",
    "\n",
    "    def forward(self, predictions, targets):\n",
    "        # Split the predictions and targets into pitch, step, and duration components\n",
    "        pitch_pred, step_pred, duration_pred = predictions[:, :128], predictions[:, 128:129], predictions[:, 129:]\n",
    "        pitch_target, step_target, duration_target = targets[:, :128], targets[:, 128:129], targets[:, 129:]\n",
    "\n",
    "        # Compute the cross-entropy loss for the pitch prediction\n",
    "        pitch_loss = F.binary_cross_entropy(pitch_pred, pitch_target)\n",
    "\n",
    "        \n",
    "        # Compute the mean squared error loss for step and duration predictions\n",
    "        step_loss = F.l1_loss(step_pred, step_target)\n",
    "        duration_loss = F.l1_loss(duration_pred, duration_target)\n",
    "\n",
    "        # Apply weights to each loss component\n",
    "        #print(pitch_loss,step_loss,duration_loss)\n",
    "        weighted_pitch_loss = pitch_loss * self.weights[0]\n",
    "        weighted_step_loss = step_loss * self.weights[1]\n",
    "        weighted_duration_loss = duration_loss * self.weights[2]\n",
    "        #print(weighted_pitch_loss,weighted_step_loss,weighted_duration_loss)\n",
    "\n",
    "        #print(pitch_loss, step_loss, duration_loss)\n",
    "        # Combine the weighted losses\n",
    "        total_loss = weighted_pitch_loss + weighted_step_loss + weighted_duration_loss\n",
    "        \n",
    "        return total_loss\n",
    "\n",
    "# Define your loss function and optimizer\n",
    "weights = torch.tensor([20,10,10]).to(device)\n",
    "#criterion = nn.MSELoss()\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = CustomWeightedLoss(weights)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a89a110",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T06:34:56.130242Z",
     "iopub.status.busy": "2024-04-14T06:34:56.129874Z",
     "iopub.status.idle": "2024-04-14T06:34:56.137335Z",
     "shell.execute_reply": "2024-04-14T06:34:56.136315Z",
     "shell.execute_reply.started": "2024-04-14T06:34:56.130213Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class LossPlotter:\n",
    "    def __init__(self,loss):\n",
    "        self.fig, self.ax = plt.subplots()\n",
    "        self.losses = list(loss)\n",
    "\n",
    "    def update_plot(self, loss):\n",
    "        self.losses.append(loss)\n",
    "        self.ax.clear()\n",
    "        self.ax.plot(self.losses, label='Accuracy')\n",
    "        self.ax.set_xlabel('Epoch')\n",
    "        self.ax.set_ylabel('Accuracy')\n",
    "        self.ax.legend()\n",
    "        self.fig.canvas.draw()\n",
    "        plt.pause(0.5)  # Pause to allow the plot to update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c047f0c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T08:28:15.590477Z",
     "iopub.status.busy": "2024-04-14T08:28:15.589457Z",
     "iopub.status.idle": "2024-04-14T08:52:47.550025Z",
     "shell.execute_reply": "2024-04-14T08:52:47.548664Z",
     "shell.execute_reply.started": "2024-04-14T08:28:15.590431Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#TRAIN\n",
    "num_epoch = 1\n",
    "n = 0\n",
    "pitch_accuracy = [0.00]\n",
    "#Loss_Plotter = LossPlotter(pitch_accuracy)\n",
    "for i in range(num_epoch):\n",
    "    torch.cuda.empty_cache()\n",
    "    #print(\"\\tInitial: \",torch.cuda.memory_allocated(),torch.cuda.memory_reserved())\n",
    "    note_input,note_output = fetch_files(n,files,20)\n",
    "    n += 20\n",
    "    # Convert your data to PyTorch tensors (assuming you already have network_input and network_output)\n",
    "    network_input_tensor = torch.tensor(note_input, dtype=torch.float32).to(device)\n",
    "    network_output_tensor = torch.tensor(note_output, dtype=torch.float32).to(device)\n",
    "\n",
    "    # Create a PyTorch dataset and data loader\n",
    "    dataset = torch.utils.data.TensorDataset(network_input_tensor, network_output_tensor)\n",
    "    del network_input_tensor\n",
    "    del network_output_tensor\n",
    "    # Define the size of the training and testing datasets\n",
    "    test_size = 0.2  # You can adjust this as needed\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [len(dataset) - int(len(dataset) * test_size), int(len(dataset) * test_size)])\n",
    "    del dataset\n",
    "    # Create data loaders for training and testing sets\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "    del train_dataset\n",
    "    del test_dataset\n",
    "    #print(\"\\tBefore loop: \",torch.cuda.memory_allocated(),torch.cuda.memory_reserved())\n",
    "    # Training loop    \n",
    "    num_small_epochs = 200\n",
    "    for epoch in range(num_small_epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "        running_loss = 0.0\n",
    "        for inputs, targets in tqdm(train_loader, desc=f'Epoch {i} Prev_accuracy {pitch_accuracy[-1]:.4} small_epoch {epoch+1}/{num_small_epochs}', leave=False):\n",
    "        #for inputs, targets in train_loader:\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Compute the loss\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()       \n",
    "            optimizer.step()\n",
    "            # Accumulate the loss\n",
    "            running_loss += loss.item()\n",
    "        #print(\"\\tAfter loop: \",torch.cuda.memory_allocated(),torch.cuda.memory_reserved())\n",
    "\n",
    "        # Print the average loss for the epoch\n",
    "        print(f'Epoch [{epoch+1}/{num_small_epochs}], Loss: {running_loss / len(train_loader)}')\n",
    "        #print(\"Testing Accuracy\")\n",
    "        #print(accuracy(test_loader),\"%\")\n",
    "        \n",
    "        accuracy_value = accuracy(model,train_loader)\n",
    "        pitch_accuracy.append(accuracy_value)\n",
    "        torch.save(model.state_dict(), '/kaggle/working/model_parameters.pth')\n",
    "        #Loss_Plotter.update_plot(accuracy_value)\n",
    "\n",
    "    del train_loader,test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61936b24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T08:53:03.813794Z",
     "iopub.status.busy": "2024-04-14T08:53:03.813172Z",
     "iopub.status.idle": "2024-04-14T08:53:04.633210Z",
     "shell.execute_reply": "2024-04-14T08:53:04.632400Z",
     "shell.execute_reply.started": "2024-04-14T08:53:03.813760Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Loss_Plotter = LossPlotter(pitch_accuracy)\n",
    "Loss_Plotter.update_plot(pitch_accuracy[-1])\n",
    "#torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bac99c8",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-14T06:08:23.155671Z",
     "iopub.status.idle": "2024-04-14T06:08:23.156068Z",
     "shell.execute_reply": "2024-04-14T06:08:23.155900Z",
     "shell.execute_reply.started": "2024-04-14T06:08:23.155884Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(next(model.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4d678a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T09:04:00.991650Z",
     "iopub.status.busy": "2024-04-14T09:04:00.990730Z",
     "iopub.status.idle": "2024-04-14T09:04:01.004684Z",
     "shell.execute_reply": "2024-04-14T09:04:01.003687Z",
     "shell.execute_reply.started": "2024-04-14T09:04:00.991613Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '/kaggle/working/parameters.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb95310",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T08:02:56.023377Z",
     "iopub.status.busy": "2024-04-14T08:02:56.022970Z",
     "iopub.status.idle": "2024-04-14T08:02:56.035351Z",
     "shell.execute_reply": "2024-04-14T08:02:56.034360Z",
     "shell.execute_reply.started": "2024-04-14T08:02:56.023344Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('/kaggle/working/parameters.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea98b98",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-14T06:08:23.160314Z",
     "iopub.status.idle": "2024-04-14T06:08:23.160673Z",
     "shell.execute_reply": "2024-04-14T06:08:23.160519Z",
     "shell.execute_reply.started": "2024-04-14T06:08:23.160504Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy(test_loader)\n",
    "accuracy(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153b3a5d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**TESTING WITH ANOTHER MUSIC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559eb058",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-14T06:08:23.163924Z",
     "iopub.status.idle": "2024-04-14T06:08:23.164291Z",
     "shell.execute_reply": "2024-04-14T06:08:23.164134Z",
     "shell.execute_reply.started": "2024-04-14T06:08:23.164119Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_accuracy = []\n",
    "fail = 0\n",
    "n = 0\n",
    "print(len(files))\n",
    "for file in files:\n",
    "    if(n%10 == 0):\n",
    "        print(n)\n",
    "    n += 1\n",
    "    #print(\"Iteration \",n+1,\"\\n\\tInitial: \",torch.cuda.memory_allocated(),torch.cuda.memory_reserved())\n",
    "    note_input_test,note_output_test = fetch_files(n,files,1)\n",
    "    if(len(note_input_test)==0):\n",
    "        continue\n",
    "\n",
    "    network_input_test_tensor = torch.tensor(note_input_test, dtype=torch.float32).to(device)\n",
    "    network_output_test_tensor = torch.tensor(note_output_test, dtype=torch.float32).to(device)\n",
    "    # Create a PyTorch dataset and data loader\n",
    "    #print(\"\\tSecond step: \",torch.cuda.memory_allocated(),torch.cuda.memory_reserved())\n",
    "    dataset = torch.utils.data.TensorDataset(network_input_test_tensor, network_output_test_tensor)\n",
    "    del network_input_test_tensor,network_output_test_tensor\n",
    "    #print(\"\\tThird step: \",torch.cuda.memory_allocated(),torch.cuda.memory_reserved())\n",
    "    test2_loader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "    del dataset\n",
    "    #print(\"\\tFourth step: \",torch.cuda.memory_allocated(),torch.cuda.memory_reserved())\n",
    "\n",
    "    del test2_loader\n",
    "    #print(\"\\tEnd: \",torch.cuda.memory_allocated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc314c7",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-14T06:08:23.165802Z",
     "iopub.status.idle": "2024-04-14T06:08:23.166136Z",
     "shell.execute_reply": "2024-04-14T06:08:23.165981Z",
     "shell.execute_reply.started": "2024-04-14T06:08:23.165967Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Number of failed midi files: \",fail)\n",
    "Loss_Plotter = LossPlotter(file_accuracy)\n",
    "Loss_Plotter.update_plot(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abf7fd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T09:03:04.858989Z",
     "iopub.status.busy": "2024-04-14T09:03:04.858040Z",
     "iopub.status.idle": "2024-04-14T09:03:05.042271Z",
     "shell.execute_reply": "2024-04-14T09:03:05.041219Z",
     "shell.execute_reply.started": "2024-04-14T09:03:04.858949Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_name = [\"/kaggle/input/musicnet-dataset/musicnet_midis/musicnet_midis/Beethoven/2313_qt15_1.mid\"]\n",
    "note_input_test,note_output_test = fetch_files(n,[files[random.randint(21,100)]],1)\n",
    "\n",
    "network_input_test_tensor = torch.tensor(note_input_test, dtype=torch.float32).to(device)\n",
    "network_output_test_tensor = torch.tensor(note_output_test, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f9ea0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T08:54:01.210853Z",
     "iopub.status.busy": "2024-04-14T08:54:01.210470Z",
     "iopub.status.idle": "2024-04-14T08:54:01.221689Z",
     "shell.execute_reply": "2024-04-14T08:54:01.220554Z",
     "shell.execute_reply.started": "2024-04-14T08:54:01.210822Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def notes_to_midi(notes, output_file):\n",
    "\n",
    "    midi_data = pretty_midi.PrettyMIDI()\n",
    "    \n",
    "    instruments_dict = {}\n",
    "\n",
    "    prev_start = 0\n",
    "    for note in notes:\n",
    "        #instrument_number = note['instrument']\n",
    "        #_, instrument_number = note[:128].max(dim=0)\n",
    "        instrument_number = 0\n",
    "        #print(instrument_number)\n",
    "        instrument_number = int(instrument_number)\n",
    "        \n",
    "        if instrument_number not in instruments_dict:\n",
    "            instruments_dict[instrument_number] = pretty_midi.Instrument(program=instrument_number)\n",
    "        \n",
    "        # Get the Instrument object from the dictionary\n",
    "        instrument = instruments_dict[instrument_number]\n",
    "\n",
    "        # Extract pitch, step, and duration from the note\n",
    "        _, pitch = note[:128].max(dim=0)\n",
    "        #pitch = note[-3]\n",
    "        step = note[-2]\n",
    "        #step = 0.4\n",
    "        duration = note[-1]\n",
    "        #duration = 0.3\n",
    "        \n",
    "        # Calculate start time and end time based on step and duration\n",
    "        start_time = prev_start + step\n",
    "        end_time = start_time + duration\n",
    "        prev_start = start_time\n",
    "\n",
    "        # Create a Note object and add it to the Instrument\n",
    "        midi_note = pretty_midi.Note(\n",
    "            velocity=100,  # Adjust the velocity (volume) of the note here if needed\n",
    "            pitch=int(pitch),\n",
    "            start=float(start_time),\n",
    "            end=float(end_time)\n",
    "        )\n",
    "        #print(midi_note, start_time, end_time)\n",
    "        instrument.notes.append(midi_note)\n",
    "\n",
    "    # Add all instruments to the PrettyMIDI object\n",
    "    for instrument_number, instrument in instruments_dict.items():\n",
    "        midi_data.instruments.append(instrument)\n",
    "\n",
    "    # Write the MIDI data to a file\n",
    "    midi_data.write(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7031e99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T09:03:09.278931Z",
     "iopub.status.busy": "2024-04-14T09:03:09.278234Z",
     "iopub.status.idle": "2024-04-14T09:03:09.728909Z",
     "shell.execute_reply": "2024-04-14T09:03:09.727856Z",
     "shell.execute_reply.started": "2024-04-14T09:03:09.278898Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_notes(model, initial_notes, num_notes_to_generate):\n",
    "      \n",
    "    generated_notes = initial_notes.clone().to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient calculation since we're only predicting\n",
    "        for _ in range(num_notes_to_generate):\n",
    "            #print(generated_notes.shape)\n",
    "            input_sequence = generated_notes[-50:].unsqueeze(dim=0)\n",
    "            \n",
    "            # Predict the next note\n",
    "            predictions = model(input_sequence)\n",
    "            #_, predicted_instruments = predictions[:, :128].max(dim=1)\n",
    "            #_, predicted_pitch = predictions[:, 128:256].max(dim=1)          \n",
    "            _, predicted_pitch = predictions.max(dim=1)\n",
    "            # Append the predicted note to the generated sequence\n",
    "            generated_notes = torch.cat((generated_notes, predictions), dim=0)\n",
    "    \n",
    "    return generated_notes \n",
    "generated_sequence = generate_notes(model, network_input_test_tensor[0], 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1890098b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T09:03:12.913124Z",
     "iopub.status.busy": "2024-04-14T09:03:12.912097Z",
     "iopub.status.idle": "2024-04-14T09:03:12.966244Z",
     "shell.execute_reply": "2024-04-14T09:03:12.965343Z",
     "shell.execute_reply.started": "2024-04-14T09:03:12.913083Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "notes_to_midi(generated_sequence,\"Fourth_Music.mid\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1167622,
     "sourceId": 1956211,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4677038,
     "sourceId": 7952691,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30673,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-14T09:04:45.359284",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
